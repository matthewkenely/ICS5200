{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\n",
    "    'angry',\n",
    "    'disgust',\n",
    "    'fear',\n",
    "    'happy',\n",
    "    'neutral',\n",
    "    'sad',\n",
    "    'surprise'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, root_dir, emotions, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        for i, emotion in enumerate(emotions):\n",
    "            emotion_dir = os.path.join(root_dir, emotion)\n",
    "            if os.path.isdir(emotion_dir):  # Ensure it's a directory\n",
    "                for image_name in os.listdir(emotion_dir):\n",
    "                    image_path = os.path.join(emotion_dir, image_name)\n",
    "                    self.images.append(image_path)\n",
    "                    self.labels.append(i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        image = Image.open(image_path).convert('L')  # Open as grayscale\n",
    "        # Convert to tensor\n",
    "        image = transforms.ToTensor()(image)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(EmotionClassifier, self).__init__()\n",
    "        \n",
    "        # Load the pre-trained ResNet50 model\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "        # Modify the ResNet model to accept grayscale images\n",
    "        # Change the first convolution layer to accept 1 channel instead of 3\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "        # Remove the final fully connected layer\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])  # Remove the last layer\n",
    "\n",
    "        # Add additional layers: 2 fully connected layers and an output layer\n",
    "        self.fc1 = nn.Linear(2048, 512)  # 2048 is the output of the last ResNet layer\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "        # Optional: Add dropout for regularization\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the ResNet backbone\n",
    "        x = self.resnet(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output from ResNet\n",
    "\n",
    "        # Forward pass through the additional fully connected layers\n",
    "        x = self.dropout(self.fc1(x))\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/unet/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/unet/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Training Epoch 1/50:  25%|██▍       | 221/901 [00:24<01:14,  9.12batch/s, loss=1.84]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m     50\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 51\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     54\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mrunning_loss \u001b[38;5;241m/\u001b[39m (pbar\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Update loss in the progress bar\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/unet/lib/python3.9/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/unet/lib/python3.9/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/unet/lib/python3.9/site-packages/torch/optim/adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    211\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    213\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    214\u001b[0m         group,\n\u001b[1;32m    215\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m         state_steps,\n\u001b[1;32m    221\u001b[0m     )\n\u001b[0;32m--> 223\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/anaconda3/envs/unet/lib/python3.9/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/unet/lib/python3.9/site-packages/torch/optim/adam.py:784\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 784\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/unet/lib/python3.9/site-packages/torch/optim/adam.py:379\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    378\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 379\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[1;32m    382\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Define constants\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_CLASSES = 7\n",
    "ROOT_DIR = './images'  # Adjust based on your dataset structure\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalization for grayscale\n",
    "])\n",
    "\n",
    "# Initialize datasets and dataloaders\n",
    "train_dataset = EmotionDataset(root_dir=os.path.join(ROOT_DIR, 'train'), emotions=emotions, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = EmotionDataset(root_dir=os.path.join(ROOT_DIR, 'validation'), emotions=emotions, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = EmotionClassifier(num_classes=NUM_CLASSES)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Check if GPU is available\n",
    "# device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Use tqdm to create a progress bar for training\n",
    "    with tqdm(total=len(train_loader), desc=f'Training Epoch {epoch + 1}/{NUM_EPOCHS}', unit='batch') as pbar:\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix(loss=running_loss / (pbar.n + 1))  # Update loss in the progress bar\n",
    "            pbar.update(1)  # Increment the progress bar\n",
    "\n",
    "    # Average loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch + 1}/{NUM_EPOCHS}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Use tqdm to create a progress bar for validation\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(val_loader), desc='Validation', unit='batch') as pbar:\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                pbar.update(1)  # Increment the progress bar\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct / total\n",
    "    print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "print('Training Complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6941,  0.6706,  0.6627,  ..., -0.7569, -0.6392, -0.2863],\n",
       "          [ 0.6941,  0.7176,  0.6706,  ..., -0.8118, -0.7882, -0.4667],\n",
       "          [ 0.6706,  0.7098,  0.7412,  ..., -0.8667, -0.8118, -0.4275],\n",
       "          ...,\n",
       "          [ 0.8824,  0.9216,  0.9216,  ...,  0.4353,  0.4039,  0.4275],\n",
       "          [ 0.8745,  0.8824,  0.9216,  ...,  0.4196,  0.4118,  0.4588],\n",
       "          [ 0.9294,  0.8667,  0.8980,  ...,  0.4745,  0.4745,  0.4824]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make new predictions\n",
    "model.eval()\n",
    "test_dataset = EmotionDataset(root_dir=os.path.join(ROOT_DIR, 'validation'), emotions=emotions, transform=transform)\n",
    "\n",
    "r = randint(0, len(test_dataset) - 1)\n",
    "\n",
    "# Select a random image from the dataset\n",
    "image, label = test_dataset[r]\n",
    "image = image.unsqueeze(0).to(device)\n",
    "\n",
    "# Perform a forward pass\n",
    "output = model(image)\n",
    "_, predicted = torch.max(output.data, 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image.cpu().squeeze().numpy(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(f'Predicted: {emotions[predicted.item()]}, Actual: {emotions[label]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
